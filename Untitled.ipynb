{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5558dcca-dde4-44fc-b68c-0b8679a83dbb",
   "metadata": {},
   "source": [
    "# Independent Lab: Manipulating Data\n",
    "\n",
    "**Intro to Python**  \n",
    "**Manipulating Data**  \n",
    "**Cody Thompson**  \n",
    "**Date:** 4/14/2025\n",
    "\n",
    "Welcome to my notebook for the Manipulating Data lab! In this notebook, I will be working with two datasets: `CaliforniaHospitalData.csv` and `CaliforniaHospitalData_Personnel.txt`. My task is to pre-process and clean the data, merge the two datasets, filter and rename columns, and perform various data manipulations to prepare the data for analysis by the Business Intelligence team.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7705ab3f-5d6f-4275-ad5a-bca419e4780a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged DataFrame Preview:\n",
      "   HospitalID                              Name         Zip TypeControl  \\\n",
      "0       45740                  Mammoth Hospital  93546-0660    District   \n",
      "1       12145  Victor Valley Community Hospital       92392  Non Profit   \n",
      "2       25667        Pioneers Memorial Hospital       92227    District   \n",
      "3       46996      Ridgecrest Regional Hospital       93555  Non Profit   \n",
      "4       37393        Barstow Community Hospital       92311    Investor   \n",
      "\n",
      "      Teaching DonorType  NoFTE    NetPatRev    InOperExp   OutOperExp  ...  \\\n",
      "0  Small/Rural   Charity  327.0  135520.2186  20523425.53  34916220.47  ...   \n",
      "1  Small/Rural   Charity  345.0  136156.6913  33447542.78  20348596.22  ...   \n",
      "2  Small/Rural   Charity  601.2  197094.2541  37254178.67  37832448.33  ...   \n",
      "3  Small/Rural   Charity  400.0  139170.3798  23385570.10  24661355.90  ...   \n",
      "4  Small/Rural   Charity  262.0  116797.8306  13684502.49  15159986.51  ...   \n",
      "\n",
      "   AvlBeds   LastName  FirstName Gender             PositionTitle  \\\n",
      "0       15        Web      David      M  Safety Inspection Member   \n",
      "1       99  Rodriguez       Jose      M   Regional Representative   \n",
      "2      107    Adamson      David      M   Regional Representative   \n",
      "3       55    Roberts    Melissa      F  Safety Inspection Member   \n",
      "4       42      Iwata      Akira      M   Regional Representative   \n",
      "\n",
      "  Compensation MaxTerm  StartDate         Phone                         Email  \n",
      "0        23987       2   1/1/2012  785-532-2452     david.web@comenitymed.com  \n",
      "1        46978       4   1/1/2009  405-744-2238  jose.rodriguez@edihealth.com  \n",
      "2        46978       4   1/1/2012  785-532-7573    david.adamson@txbiomed.net  \n",
      "3        23987       2   1/1/2009  785-532-9779  melissa.roberts@txbiomed.net  \n",
      "4        46978       4   1/1/2011  801-611-9161           akira.iwata@hsu.edu  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "from datetime import datetime  \n",
    "\n",
    "# Set Working Directory\n",
    "os.chdir('C:\\\\Users\\\\cthom\\\\Downloads\\\\BGEN 632 Intro to Python\\\\GitHub_Repos\\\\Week 7\\\\week7labs\\\\data')\n",
    "\n",
    "#~~~~~~~~~~~ Accessing and Merging Data ~~~~~~~~~~~~~\n",
    "\n",
    "# Load the hospital data from the CSV file\n",
    "hospital_df = pd.read_csv('CaliforniaHospitalData.csv')\n",
    "\n",
    "# Load the personnel data from the text file\n",
    "personnel_df = pd.read_csv('CaliforniaHospitalData_Personnel.txt', sep=\"\\t\")\n",
    "\n",
    "# Merge the hospital and personnel data on the 'HospitalID' column\n",
    "merged_df = pd.merge(hospital_df, personnel_df, on='HospitalID')\n",
    "\n",
    "# Remove unwanted columns as specified\n",
    "merged_df.drop(columns=['Work_ID', 'PositionID', 'Website'], inplace=True)\n",
    "\n",
    "# Show the first few rows of the merged data for verification\n",
    "print(\"Merged DataFrame Preview:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9dd05f63-2e07-45b2-b2d3-5efb3214bf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame:\n",
      "Empty DataFrame\n",
      "Columns: [HospitalID, Name, Zip, TypeControl, Teaching, DonorType, NoFTE, NetPatRev, InOperExp, OutOperExp, OperRev, OperInc, AvlBeds, LastName, FirstName, Gender, PositionTitle, Compensation, MaxTerm, StartDate, Phone, Email]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 22 columns]\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(filtered_df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Export the filtered data as a tab-delimited text file\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m filtered_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/hospital_data_new.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData exported successfully!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     check_parent_directory(\u001b[38;5;28mstr\u001b[39m(handle))\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "#~~~~~~~~~~~ Filtering and Exporting Data ~~~~~~~~~~~~~\n",
    "\n",
    "# Filter hospitals that are 'Small/Rural' and have at least 15 beds with no negative operating income\n",
    "filtered_df = merged_df[(merged_df['TypeControl'] == 'Small/Rural') &  # Filter based on Small/Rural TypeControl\n",
    "                        (merged_df['AvlBeds'] >= 15) &  # Filter based on available beds\n",
    "                        (merged_df['OperInc'] >= 0)]  # Exclude hospitals with negative operating income\n",
    "\n",
    "# Display the filtered DataFrame to confirm the results\n",
    "print(\"Filtered DataFrame:\")\n",
    "print(filtered_df.head())\n",
    "\n",
    "# Export the filtered data as a tab-delimited text file\n",
    "filtered_df.to_csv('data/hospital_data_new.txt', sep='\\t', index=False)\n",
    "\n",
    "print(\"Data exported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b1b086-2085-4cb6-b998-42d06eae849b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~ Renaming Columns ~~~~~~~~~~~~~\n",
    "\n",
    "# Rename the columns as required by the assignment\n",
    "hospital_data_new.rename(columns={\n",
    "    'NoFTE': 'FullTimeCount',\n",
    "    'NetPatRev': 'NetPatientRevenue',\n",
    "    'InOperExp': 'InpatientOperExp',\n",
    "    'OutPerExp': 'OutpatientOperExp',\n",
    "    'OperRev': 'Operating_Revenue',\n",
    "    'OperInc': 'Operating_Income'\n",
    "}, inplace=True)\n",
    "\n",
    "# Show the updated DataFrame with renamed columns\n",
    "print(\"Renamed Columns Preview:\")\n",
    "print(hospital_data_new.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e2660f-9480-4acc-b917-d9a6e606aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~ Inserting Records ~~~~~~~~~~~~~\n",
    "\n",
    "# Define new employee data for yourself as a new position in two hospitals\n",
    "new_employee_data = pd.DataFrame({\n",
    "    'HospitalID': [hospital_data_new['HospitalID'].iloc[0], hospital_data_new['HospitalID'].iloc[1]],  # Use the first two hospitals\n",
    "    'Work_ID': [None, None],  # Placeholder as Work_ID will be generated\n",
    "    'LastName': ['Thompson', 'Thompson'],  # Your last name\n",
    "    'FirstName': ['Cody', 'Cody'],  # Your first name\n",
    "    'Gender': ['M', 'M'],  # Gender\n",
    "    'PositionTitle': ['Regional Representative', 'State Board Representative'],\n",
    "    'Compensation': [46978, 89473],\n",
    "    'MaxTerm': [4, 3],\n",
    "    'StartDate': [datetime.now(), datetime.now()],  # Current date\n",
    "    'PositionID': [None, None]  # Placeholder for PositionID\n",
    "})\n",
    "\n",
    "# Concatenate new employee records with the existing data\n",
    "new_merge = pd.concat([hospital_data_new, new_employee_data], ignore_index=True)\n",
    "\n",
    "# Display the updated DataFrame with the newly inserted records\n",
    "print(\"Newly Inserted Records Preview:\")\n",
    "print(new_merge.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60887189-3b71-446b-8c0e-903842e8814e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~ Filtering Data ~~~~~~~~~~~~~\n",
    "\n",
    "# Filtering non-profit hospitals with more than 250 employees and exclude those with NetPatientRevenue <= 109000\n",
    "filtered_non_profit = new_merge[(new_merge['TypeControl'] == 'Non-profit') &\n",
    "                                (new_merge['FullTimeCount'] > 250) & \n",
    "                                (new_merge['NetPatientRevenue'] > 109000)]\n",
    "\n",
    "# Show the filtered non-profit hospitals\n",
    "print(\"Filtered Non-Profit Hospitals Preview:\")\n",
    "print(filtered_non_profit)\n",
    "\n",
    "# Filtering Regional Representatives with Operating Income > 100,000\n",
    "regional_representatives = new_merge[(new_merge['PositionTitle'] == 'Regional Representative') &\n",
    "                                     (new_merge['Operating_Income'] > 100000)]\n",
    "\n",
    "# Show the filtered Regional Representatives\n",
    "print(\"Filtered Regional Representatives Preview:\")\n",
    "print(regional_representatives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08da785-7516-49a6-91bd-95644a065f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~ Convert Date-Time Data ~~~~~~~~~~~~~\n",
    "\n",
    "# Convert the 'StartDate' column to datetime\n",
    "new_merge['StartDate'] = pd.to_datetime(new_merge['StartDate'])\n",
    "\n",
    "# Confirm the changes by displaying the data types and the first few records of the 'StartDate' column\n",
    "print(\"Data Types After Conversion:\")\n",
    "print(new_merge.dtypes)\n",
    "\n",
    "print(\"First 5 records of StartDate Column:\")\n",
    "print(new_merge[['StartDate']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
